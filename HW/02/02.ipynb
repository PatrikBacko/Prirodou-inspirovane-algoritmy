{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\n",
    "Za domácí úkol budete mít vytvořit si vlastní libovolný dataset na image classfication task, abyste si vyzkoušeli, že vyrábět data není úplně snadné. Dataset by měl mít aspoň 5 různých tříd ke klasifikaci a ke každé nějaké rozumné desítky obrázků.\n",
    "\n",
    "Až budete mít data, tak si na nich zkuste image classification task. Jak už jsem zmínila výše, trénovat celou konvoluční síť od začátku by bylo početně náročné, proto budete mít za úkol si vybrat 3 z už predtrénovaných modelů například [odsud](https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/) a přetrénovat je tak, aby uměly klasifikovat vámi vytvořená data.\n",
    "\n",
    "Můžete si na vašich datech i zkusit natrénovat podobnou (klidně i stejnou) jednoduchou konvoluční síť, kterou jsme používali před na MNISTu výše a schválně se podívat, jak moc bude špatná oproti těm už předtrénovaným.\n",
    "\n",
    "Své řešení mi pošlete emailem do stanoveného deadline. Pro sepsání popisu vašeho datasetu, zvolených modelů a rozboru výsledků použijte [tento template](https://github.com/kackamac/Prirodou-inspirovane-algoritmy/blob/master/08_konvoluce/DU2_konvolucni_site.pdf). Řešení by mělo obsahovat:\n",
    "1. slovní popis vašich dat (jaké máte labely, kolik každý obsahuje obrázků, velikost obrázků, zdůvodnění volby datasetu)\n",
    "2. váš kód\n",
    "3. slovní popis výsledků a porovnání modelů (jaké jste použili, jak byl který úspěšný (accuraccy všech modelů na testovací množině, sepsaná třeba v nějaké pěkné tabulce) a který byl nejlepší)\n",
    "4. vámi vytvořený předzpracovaný dataset (obrázky by měly být malé, takže by neměl být problém s posláním)\n",
    "\n",
    "Pár tipů\n",
    "- bylo by dobré mít u všech tříd stejný počet obrázků\n",
    "- obrázky bude potřeba převést do nějakého jednotného rozumně malého rozměru (například 128 x 128 pixelů)\n",
    "- když budete používat předtrénované sítě, tak ty vaše obrázky by měly být stejně velké jako ty, na kterých byla trénovaná ta  síť původně\n",
    "- zároveň bude potřeba je rozdělit na dvě disjunktní množiny -- trénovací a testovací (trénovací na přetrénovaní modelů a testovací na jejich vyhodnocení)\n",
    "- model se dá přetrénovat například tak, že si nahradíte poslední nebo několik posledních vrstev vlastními, které budete přetrénovávat podle vašich dat\n",
    "- pokud se vám model nedaří přetrénovat, aby dosahoval nějakých rozumných výsledků, zkuste použít nějakou augmentaci dat a trénovat na větších datech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.datasets import cifar10, mnist, fashion_mnist\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense, Activation, Resizing, Rescaling, RandomFlip, RandomRotation\n",
    "from tensorflow.keras.activations import linear, relu\n",
    "from tensorflow.nn import softmax\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 files belonging to 2 classes.\n",
      "Using 27 files for training.\n",
      "Using 11 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  RandomFlip(\"horizontal_and_vertical\"),\n",
    "  RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import ResNet50\n",
    "# base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "classes = 2\n",
    "\n",
    "model = tf.keras.models.Sequential([])\n",
    "\n",
    "model.add(resize_and_rescale)\n",
    "model.add(data_augmentation)\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(units=250, activation=relu))\n",
    "model.add(Dense(units=classes, activation=linear, name='logits'))\n",
    "model.add(Activation(activation=softmax))\n",
    "# model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 33s 33s/step - loss: 0.8249 - accuracy: 0.5556 - val_loss: 11.4151 - val_accuracy: 0.4545\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 11.7519 - accuracy: 0.4444 - val_loss: 6.1531 - val_accuracy: 0.4545\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 6.3916 - accuracy: 0.4444 - val_loss: 1.7416 - val_accuracy: 0.5455\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.7291 - accuracy: 0.5556 - val_loss: 4.0327 - val_accuracy: 0.5455\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.9119 - accuracy: 0.5556 - val_loss: 3.3258 - val_accuracy: 0.5455\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.2471 - accuracy: 0.5556 - val_loss: 0.7971 - val_accuracy: 0.5455\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8196 - accuracy: 0.5556 - val_loss: 3.0680 - val_accuracy: 0.4545\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.2688 - accuracy: 0.4444 - val_loss: 3.6564 - val_accuracy: 0.4545\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.8849 - accuracy: 0.4444 - val_loss: 1.7985 - val_accuracy: 0.4545\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.9675 - accuracy: 0.4444 - val_loss: 1.3210 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228bfe3e970>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open('dog.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
